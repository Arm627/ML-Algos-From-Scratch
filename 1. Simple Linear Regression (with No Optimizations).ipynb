{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center;\"><b>Implementing Simple Linear Regression From Scratch (No Optimizations)</b> </h3>\n",
    "<h5 style=\"text-align: center;\"> This notebook is adapted and adds onto this wonderful tutorial by Jason Brownlee found here:\n",
    "<br><a href=\"https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/\" target=\"_blank\">https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/</a></h5>\n",
    "\n",
    "<h5 style=\"text-align: center;\"> <a href=\"https://en.wikipedia.org/wiki/Simple_linear_regression\" target=\"_blank\">https://en.wikipedia.org/wiki/Simple_linear_regression</a></h5>\n",
    "<h5 style=\"text-align: center;\">Linear regression assumes a linear or straight line relationship between the input variables (X) and the single output variable (y). </h5>\n",
    "\n",
    "<h5 style=\"text-align: center;\"><code>y = &alpha; x + &beta; </code></h5>\n",
    "<h5 style=\"text-align: center;\"> &alpha; and &beta; are estimated from the training data </h5>\n",
    "<h5 style=\"text-align: center;\"> We can estimate the coefficients as follows: </h5>\n",
    "$$ \\hat \\alpha = \\bar{y} - \\hat \\beta \\bar{x} $$\n",
    "<h5 style=\"text-align: center;\"> In code: <code>&alpha; = mean(y) - &beta; mean(x) </code></h5>\n",
    "$$ \\hat \\beta = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n",
    "<h5 style=\"text-align: center;\"> In code: <code>&beta; = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 ) </code></h5>\n",
    "<h5 style=\"text-align: center;\"> Where the i refers to the value of the ith value of the input x or output y. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63,) (63,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pandas.read_csv(\"Data\\\\linear_data.csv\")\n",
    "data_X = data['X'].to_numpy()\n",
    "data_Y = data['Y'].to_numpy()\n",
    "print(data_X.shape, data_Y.shape)\n",
    "plt.scatter(data_Y, data_X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center;\"> 1. Calculate Mean and Variance </h4>\n",
    "\n",
    "$$ \\text{Mean: } \\bar{X} = \\frac{\\sum_{i=1}^{n} x_i}{n} $$\n",
    "<h5 style=\"text-align: center;\"> n is number of terms </h5>\n",
    "<h5 style=\"text-align: center;\"> In code: <code>mean(x) = sum(x) / count(x) </code></h5>\n",
    "<h5 style=\"text-align: center;\"><a href=\"https://en.wikipedia.org/wiki/Mean\" target=\"_blank\">https://en.wikipedia.org/wiki/Mean</a></h5>\n",
    "$$ \\text{Variance: } \\sigma^2 = \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $$\n",
    "<h5 style=\"text-align: center;\"> In code: <code>&sigma; = sum(x - mean(x))**2)</code></h5>\n",
    "<h5 style=\"text-align: center;\">Variance measures how far a set of numbers are spread out from their average value.</h5>\n",
    "<h5 style=\"text-align: center;\"><a href=\"https://en.wikipedia.org/wiki/Variance\" target=\"_blank\">https://en.wikipedia.org/wiki/Variance</a></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of inputs: 22.904761904761905 Mean of outputs: 48.35079365079365\n",
      "Variance of inputs: 33809.42857142858 Variance of outputs: 156445.4174603175\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Mean and Variance\n",
    "\"\"\"\n",
    "from math import pow, sqrt\n",
    "def _mean(values):\n",
    "    \"\"\"\n",
    "    Input 1d array (values) -> Output a scalar value, the mean\n",
    "    \"\"\"\n",
    "    return (sum(values) / float(len(values)))\n",
    "\n",
    "def _variance(values, mean):\n",
    "    \"\"\"\n",
    "    Input 1d array (values) and scalar value (mean) -> Output scalar value, the variance\n",
    "    \"\"\"\n",
    "    var = []\n",
    "    for x in values:\n",
    "        var.append(pow((x - mean), 2))\n",
    "    return sum(var)\n",
    "\n",
    "mean_x = _mean(data_X)\n",
    "mean_y = _mean(data_Y)\n",
    "print(\"Mean of inputs:\", mean_x, \"Mean of outputs:\", mean_y)\n",
    "print(\"Variance of inputs:\", _variance(data_X, mean_x), \"Variance of outputs:\", _variance(data_Y, mean_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center;\"> 2. Calculate Covariance </h4>\n",
    "<h5 style=\"text-align: center;\">The covariance of two groups of numbers describes how those numbers change together.</h5>\n",
    "<h5 style=\"text-align: center;\">Covariance is a generalization of correlation. Correlation describes the relationship between two groups of numbers, whereas covariance can describe the relationship between two or more groups of numbers.</h5>\n",
    "<h5 style=\"text-align: center;\">Additionally, covariance can be normalized to produce a correlation value.</h5>\n",
    "$$ \\text{cov =} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) $$\n",
    "<h5 style=\"text-align: center;\">In code: <code>cov = sum((x(i) - mean(x)) * (y(i) - mean(y)))</code></h5>\n",
    "<h5 style=\"text-align: center;\"><a href=\"https://en.wikipedia.org/wiki/Covariance\" target=\"_blank\">https://en.wikipedia.org/wiki/Covariance</a><h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance: 70191.20476190475\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Covariance\n",
    "\"\"\"\n",
    "def _covariance(x, mean_x, y, mean_y):\n",
    "    \"\"\"\n",
    "    Input 1d array (x), Input 1d array (y), a scalar the mean of the x's (mean_x) and the mean of the y's (mean_y) -> a scalar the covariance\n",
    "    \"\"\"\n",
    "    cov = 0\n",
    "    for i in range(len(x)):\n",
    "        cov += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "    return cov\n",
    "covar = _covariance(data_X, mean_x, data_Y, mean_y)\n",
    "print(\"Covariance:\", covar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center;\"> 3. Calculate Coefficients, RMSE, and R^2 </h4><br>\n",
    "<h5 style=\"text-align: center;\"> Coefficients </h5><br>\n",
    "$$ \\hat \\beta = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n",
    "<h5 style=\"text-align: center;\"> In code: <code>&beta; = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )</code></h5><br>\n",
    "$$ \\hat \\beta \\text{=} \\frac{covariance(x, y)}{variance(x)} $$\n",
    "<h5 style=\"text-align: center;\"> In code: <code>&beta; = covariance(x, y) / variance(x)</code></h5><br>\n",
    "$$ \\hat \\alpha \\text{ = } \\bar{y} - \\hat \\beta \\bar{x} $$\n",
    "<h5 style=\"text-align: center;\">In code: <code>&alpha; = mean(y) - &beta; * mean(x)</code></h5>\n",
    "<h5 style=\"text-align: center;\"> RMSE </h5><br>\n",
    "$$ \\text{rmse} = \\sqrt{\\frac{\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2}{n}} $$ \n",
    "<h5 style=\"text-align: center;\"> In code: <code> rmse = sqrt(sum((y_pred - y_actual)**2)/n) </code></h5>\n",
    "<h5 style=\"text-align: center;\"><a href=\"https://en.wikipedia.org/wiki/Root-mean-square_deviation\" target=\"_blank\">https://en.wikipedia.org/wiki/Root-mean-square_deviation</a></h5><br>\n",
    "$$ R^2 $$\n",
    "<h5 style=\"text-align: center;\"> The coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s). </h5>\n",
    "$$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\bar{y_i})^2} $$\n",
    "$$ \\text{The numerator is the variance and the denomenator the } y_i \\text{ is the } i^{th} \\text{ value of the variable to be predicted and } \\hat{y_i} \\text{ is the predicted value.} $$\n",
    "<h5 style=\"text-align: center;\">In code: <code>1 - (sum((y - mean(y))**2)) / (sum((x - y_pred))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.798589996028177 Beta: 2.076083735447141\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Coefficients, RMSE and Evaluation\n",
    "\"\"\"\n",
    "def _coefficients(X, Y):\n",
    "    \"\"\"\n",
    "    Input 1d array (X) and 1d array (Y) -> Output alpha and beta scalar coefficients\n",
    "    \"\"\"\n",
    "    x_mean, y_mean = _mean(X), _mean(Y)\n",
    "    beta = _covariance(X, x_mean, Y, y_mean) / _variance(X, x_mean)\n",
    "    alpha = y_mean - beta * x_mean\n",
    "    return alpha, beta\n",
    "alpha, beta = _coefficients(data_X, data_Y)\n",
    "print(\"Alpha:\", alpha, \"Beta:\",beta)\n",
    "\n",
    "def _rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    Input 1d array (actual) and 1d array (predicted) -> Output scalar rmse error\n",
    "    \"\"\"\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        sum_error += pow(predicted[i] - actual[i], 2)\n",
    "    return sqrt((sum_error / float(len(actual))))\n",
    "\n",
    "def _r_squared(X, Y, predictions):\n",
    "    \"\"\"\n",
    "    Input 1d array (X) and 1d array (Y) and 1d array (predictions) -> Output scalar R^2\n",
    "    \"\"\"\n",
    "    var = _variance(Y, _mean(Y))\n",
    "    denomenator = 0.0\n",
    "    predictions = []\n",
    "    for i in range(len(data_X)):\n",
    "        predictions.append(predict(data_X, data_Y, data_X[i]))\n",
    "    for i in range(len(X)):\n",
    "        denomenator += pow((X[i] - predictions[i]), 2)\n",
    "    r_square = 1 - (var / denomenator)\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center;\"> 4. Calculate Coefficients </h4>\n",
    "<h5 style=\"text-align: center;\"><code>y = &alpha; x + &beta; </code></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. Predict\n",
    "\"\"\"\n",
    "def _predict(X, Y, pred):\n",
    "    \"\"\"\n",
    "    Input 1d array (train) and 1d array (test)\n",
    "    \"\"\"\n",
    "    beta, alpha = _coefficients(X, Y)\n",
    "    y_hat = beta + alpha * pred\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"text-align: center;\">Putting this all together with inspiration from <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" target=\"_blank\">Sklearn Linear Regression</a></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pow, sqrt\n",
    "class LinearRegressionUtils:\n",
    "    def mean(self, values):\n",
    "        \"\"\"\n",
    "        Input 1d array (values) -> Output a scalar value, the mean\n",
    "        \"\"\"\n",
    "        return (sum(values) / float(len(values)))\n",
    "\n",
    "    def variance(self, values, mean):\n",
    "        \"\"\"\n",
    "        Input 1d array (values) and scalar value (mean) -> Output scalar value, the variance\n",
    "        \"\"\"\n",
    "        var = []\n",
    "        for x in values:\n",
    "            var.append(pow((x - mean), 2))\n",
    "        return sum(var)\n",
    "    \n",
    "    def covariance(self, x, mean_x, y, mean_y):\n",
    "        \"\"\"\n",
    "        Input 1d array (x), Input 1d array (y), a scalar the mean of the x's (mean_x) and the mean of the y's (mean_y) -> a scalar the covariance\n",
    "        \"\"\"\n",
    "        cov = 0\n",
    "        for i in range(len(x)):\n",
    "            cov += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "        return cov\n",
    "    \n",
    "    def coefficients(self, X, Y):\n",
    "        \"\"\"\n",
    "        Input 1d array (X) and 1d array (Y) -> Output alpha and beta scalar coefficients\n",
    "        \"\"\"\n",
    "        x_mean, y_mean = self.mean(X), self.mean(Y)\n",
    "        beta = self.covariance(X, x_mean, Y, y_mean) / self.variance(X, x_mean)\n",
    "        alpha = y_mean - beta * x_mean\n",
    "        return alpha, beta\n",
    "    \n",
    "    def rmse(self, actual, predicted):\n",
    "        \"\"\"\n",
    "        Input 1d array (actual) and 1d array (predicted) -> Output scalar rmse error\n",
    "        \"\"\"\n",
    "        sum_error = 0.0\n",
    "        for i in range(len(actual)):\n",
    "            sum_error += pow(predicted[i] - actual[i], 2)\n",
    "        return sqrt((sum_error / float(len(actual))))\n",
    "\n",
    "    def r_squared(self, X, Y, predictions):\n",
    "        \"\"\"\n",
    "        Input 1d array (X) and 1d array (Y) and 1d array (predictions) -> Output scalar R^2\n",
    "        \"\"\"\n",
    "        var = self.variance(Y, self.mean(Y))\n",
    "        denomenator = 0.0\n",
    "        for i in range(len(X)):\n",
    "            denomenator += pow((X[i] - predictions[i]), 2)\n",
    "        r_square = 1 - (var / denomenator)\n",
    "        return r_square\n",
    "\n",
    "class LinearRegression(LinearRegressionUtils):\n",
    "    \"\"\"\n",
    "    Demo Linear Regression Class\n",
    "    \"\"\"\n",
    "    def fit(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.intercept_, self.coef_ = LinearRegressionUtils.coefficients(self, self.X, self.Y)\n",
    "        self.train_predicts = []\n",
    "        for i in range(len(X)):\n",
    "            self.train_predicts.append(self.predict(X[i]))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + self.coef_*x\n",
    "    \n",
    "    def score(self, X=None, Y=None):\n",
    "        if X == None and Y == None:\n",
    "            return LinearRegressionUtils.r_squared(self, self.X, self.Y, self.train_predicts)\n",
    "        else:\n",
    "            pass # add later\n",
    "        \n",
    "    def rmse(self):\n",
    "        return LinearRegressionUtils.rmse(self.Y, self.train_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.9569774485515175\n",
      "Alpha: 2.076083735447141\n",
      "Beta: 0.798589996028177\n",
      "Prediction: 71.38543700123097\n",
      "\n",
      "\n",
      "R^2: 0.71875\n",
      "Alhpa: 3.0\n",
      "Beta: 0.0\n",
      "[[ 9. 15.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "reg = LinearRegression()\n",
    "reg.fit(data_X, data_Y)\n",
    "print(\"R^2:\", reg.score())\n",
    "print(\"Alpha:\", reg.coef_)\n",
    "print(\"Beta:\", reg.intercept_)\n",
    "print(\"Prediction:\", reg.predict(34))\n",
    "print(\"\\n\")\n",
    "reg2 = LinearRegression()\n",
    "X = [1, 1, 1, 2, 2, 2, 2, 3]\n",
    "y = [3, 3, 3, 6, 6, 6, 6, 9]\n",
    "reg2.fit(X, y)\n",
    "print(\"R^2:\", reg2.score())\n",
    "print(\"Alhpa:\", reg2.coef_)\n",
    "print(\"Beta:\", reg2.intercept_)\n",
    "print(reg2.predict(np.array([[3, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[3.]]\n",
      "[8.8817842e-16]\n",
      "[[9.]] [[15.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: as can be seen our code is correct except for R^2 which is off (see issue 1)\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "reg3 = LinearRegression().fit(X, y)\n",
    "print(reg3.score(X, y))\n",
    "print(reg3.coef_)\n",
    "print(reg3.intercept_)\n",
    "p_3 = np.array(3).reshape(1, -1)\n",
    "p_5 = np.array(5).reshape(1, -1)\n",
    "print(reg3.predict(p_3), reg3.predict(p_5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
