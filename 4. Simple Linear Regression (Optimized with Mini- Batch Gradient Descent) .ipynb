{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center;\"><b>Implementing Simple Linear Regression From Scratch (with Mini- Batch Gradient Descent)</b> </h3>\n",
    "<h5 style=\"text-align: center;\"> This notebook is exactly the same as Notebook 3 except it uses Mini- Batch Gradient Descent instead of Stochastic Gradient Descent</h5>\n",
    "<h5 style=\"text-align: center;\"> <a href=\"https://en.wikipedia.org/wiki/Simple_linear_regression\" target=\"_blank\">https://en.wikipedia.org/wiki/Simple_linear_regression</a></h5>\n",
    "<h5 style=\"text-align: center;\">We still have <code>y = &alpha; x + &beta; </code></h5>\n",
    "<h5 style=\"text-align: center;\">And we still estimate the coeffiecients not by rewriting the formula, but by writing it in terms of a function f(&alpha;,&beta;) where &alpha; and &beta; are that in the formula.</h5>\n",
    "<h5 style=\"text-align: center;\">Again the formula we are going to make as a function is Mean Squared Error which is the square of RMSE we explored in the previous notebook</h5>\n",
    "$$ \\text{MSE = } \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $$\n",
    "$$ \\text{Where } \\hat{y_i} \\text{ we know to be } \\hat{y_i} = \\alpha x + \\beta $$\n",
    "$$ \\text{This derives to } f(\\alpha, \\beta) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\alpha x_i - \\beta)^2 $$\n",
    "$$ \\text{We want to take the min of this; so, } \\min_{\\alpha, \\beta}f(\\alpha, \\beta) $$\n",
    "$$ \\text{We now want to take the partial deriv with respect to } \\alpha \\text{ and } \\beta $$\n",
    "$$ \\frac{\\partial f}{\\partial \\alpha} = \\frac{1}{n} \\sum_{i=1}^{n} -2x_i(y_i - \\alpha x_i - \\beta) \\text{ and} $$\n",
    "<h5 style=\"text-align: center;\">In code:<code>(-2*sum(X*(Y - alpha*X - beta))) / n</code></h5>\n",
    "$$ \\frac{\\partial f}{\\partial \\beta} = \\frac{1}{n} \\sum_{i=1}^{n} -2(y_i - \\alpha x_i - \\beta) $$\n",
    "<h5 style=\"text-align: center;\">In code:<code>(-2*sum((Y - alpha*X - beta))) / n</code></h5>\n",
    "<h5 style=\"text-align: center;\">We then multiply it by some learning rate and subtract it from the previous alpha and beta</h5>\n",
    "<h5 style=\"text-align: center;\">We do this for e number of epochs and pretty soon we converge to an optimal minima.</h5>\n",
    "<h5 style=\"text-align: center;\">The difference between the two optimization is Mini- Batch only uses a subset (not 1 batch- size) sample of &alpha; and &beta;</h5>\n",
    "<h5 style=\"text-align: center;\">The code is exactly the same except batch_size > 1 </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0160559173448853 0.9628651319434623\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mini_batch_gradient_descent_for_linear_regression(X, Y, lr=0.05, epochs=1000, batch_size=3):\n",
    "    \"\"\"\n",
    "    Batch size is how many samples to choose from X and Y. Everything else is the same as Notebook 3\n",
    "    \"\"\"\n",
    "    alpha = random()\n",
    "    beta = random()\n",
    "    mse = []\n",
    "    for _ in range(epochs):\n",
    "        indexes = np.random.randint(0, len(X), batch_size) # outputs an array of size batch_size of random indexes from 0 to len(X)\n",
    "        x_s = np.take(X, indexes) # takes elements of X at given index\n",
    "        y_s = np.take(Y, indexes) # takes elements of Y at given index\n",
    "        n = len(x_s)\n",
    "        \"\"\"\n",
    "        Note: instead of all X and Y, we calculate only a subset of the X and Y array\n",
    "        \"\"\"\n",
    "        partial_of_alpha = (-2*sum(x_s*(y_s - alpha*x_s - beta))) / n\n",
    "        partial_of_beta = (-2*sum((y_s - alpha*x_s - beta))) / n\n",
    "        alpha -= lr*partial_of_alpha\n",
    "        beta -= lr*partial_of_beta\n",
    "        mse.append(sum((y_s - alpha*x_s - beta)**2)/n)\n",
    "    return alpha, beta, mse\n",
    "\n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([2, 3, 4])\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "alpha, beta, mse = mini_batch_gradient_descent_for_linear_regression(X, Y, epochs=epochs, batch_size=batch_size)\n",
    "print(alpha, beta)\n",
    "epochs_array = [x for x in range(epochs)]\n",
    "plt.plot(epochs_array, mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionUtils:\n",
    "    def coefficients(self, X, Y, lr, epochs, batch_size):\n",
    "        alpha = random()\n",
    "        beta = random()\n",
    "        for _ in range(epochs):\n",
    "            indexes = np.random.randint(0, len(X), batch_size) # outputs an array of size batch_size of random indexes from 0 to len(X)\n",
    "            x_s = np.take(X, indexes) # takes elements of X at given index\n",
    "            y_s = np.take(Y, indexes) # takes elements of Y at given index\n",
    "            n = len(x_s)\n",
    "            \"\"\"\n",
    "            Note: instead of all X and Y, we calculate only a subset of the X and Y array\n",
    "            \"\"\"\n",
    "            partial_of_alpha = (-2*sum(x_s*(y_s - alpha*x_s - beta))) / n\n",
    "            partial_of_beta = (-2*sum((y_s - alpha*x_s - beta))) / n\n",
    "            alpha -= lr*partial_of_alpha\n",
    "            beta -= lr*partial_of_beta\n",
    "        return alpha, beta\n",
    "    \n",
    "class LinearRegression(LinearRegressionUtils):\n",
    "    \"\"\"\n",
    "    Demo Linear Regression class using Mini-Batch Gradient Descent\n",
    "    \"\"\"\n",
    "    def fit(self, X, Y, lr=0.05, epochs=1000, batch_size=3):\n",
    "        \"\"\"\n",
    "        X and Y to fit, lr = learning rate, epochs = num epochs to iterate over\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.coef_, self.intercept_ = LinearRegressionUtils.coefficients(self, X=self.X, Y=self.Y, lr=self.lr, epochs=self.epochs, batch_size=batch_size)\n",
    "        self.predictions = []\n",
    "        for i in range(len(self.X)):\n",
    "            self.predictions.append(self.predict(self.X[i]))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + self.coef_ * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0000015553465922\n",
      "Beta: 0.9999964409344042\n",
      "Prediction: 35.00004932271854\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([2, 3, 4])\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, Y)\n",
    "print(\"Alpha:\", reg.coef_)\n",
    "print(\"Beta:\", reg.intercept_)\n",
    "print(\"Prediction:\", reg.predict(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: [[1.]]\n",
      "Beta: [1.]\n",
      "Prediction: [[35.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(Y).reshape(-1, 1)\n",
    "reg2 = LinearRegression().fit(X, y)\n",
    "print(\"Alpha:\", reg2.coef_)\n",
    "print(\"Beta:\", reg2.intercept_)\n",
    "print(\"Prediction:\", reg2.predict(np.array(34).reshape(1, -1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
